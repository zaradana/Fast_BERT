{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4c06ada08e68eb00ce3812085d716785e3ab399270f033abc6220370d23e963c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "zd-ner\nscan-datasources-rg\nsouthcentralus\nd35ad7f3-a6be-400c-b1db-8b70322a01a0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = \"ner_new\"\n",
    "experiment = Experiment(ws, name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-gpu', file_path = 'conda.yaml')\n",
    "\n",
    "# Specify a GPU base image\n",
    "pytorch_env.docker.enabled = True\n",
    "pytorch_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "831d1d087770406a8c552b42030ea68f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/ner_new/runs/ner_new_1606688308_21ae6f00?wsid=/subscriptions/d35ad7f3-a6be-400c-b1db-8b70322a01a0/resourcegroups/scan-datasources-rg/workspaces/zd-ner\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"run_properties\": {\"run_id\": \"ner_new_1606688308_21ae6f00\", \"created_utc\": \"2020-11-29T22:18:36.844034Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"4859a9da-ee7e-41be-b247-0bfedf9d669d\", \"azureml.git.repository_uri\": \"git@github.com:zaradana/Fast_BERT.git\", \"mlflow.source.git.repoURL\": \"git@github.com:zaradana/Fast_BERT.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"c94b021530133e64594598ec2dd98736c5b33fe5\", \"mlflow.source.git.commit\": \"c94b021530133e64594598ec2dd98736c5b33fe5\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-11-29T22:25:54.999726Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/azureml-logs/55_azureml-execution-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt?sv=2019-02-02&sr=b&sig=YC2BvHMLNqZ7pXP8HD9pAHBpsjwphunDzVC92vn4IZg%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/azureml-logs/65_job_prep-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt?sv=2019-02-02&sr=b&sig=OySJcBK2jiv3LlqIFaMlxYrkrGiFLu%2Be0TJWY9bGb5g%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=aFhcgLb0oJtGVBS19x9HfJz5T85vFighIEeJwo9oChw%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\", \"azureml-logs/75_job_post-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/azureml-logs/75_job_post-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt?sv=2019-02-02&sr=b&sig=FIJWiBn6ufF3SLh4pXlEPI2mXe9m9NXMZ0EzO7C%2BtJQ%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\", \"azureml-logs/process_info.json\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=Okn5BtWggZIavdVmU4O422%2FGmx8Q96S%2Fy5Ckm0JKjTQ%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\", \"azureml-logs/process_status.json\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=4RDEh1mEVEz87mJdHAIcagYNcesaQzJHmh5zcfqiOfk%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\", \"logs/azureml/101_azureml.log\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/logs/azureml/101_azureml.log?sv=2019-02-02&sr=b&sig=9ZdPiBfzV7b1e3gOASlyjbiPjlfHrtL0NwJZX%2FXmDLo%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=6KlqtG0F1Y6j%2BWGWeU9yOzXtQkrt9icXBAzrM03Ze%2Fc%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://zdner7033739836.blob.core.windows.net/azureml/ExperimentRun/dcid.ner_new_1606688308_21ae6f00/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=69BTeNGkzyUMPShQ8A1hXhnNgKcn69ubKjWFUM%2FDTb4%3D&st=2020-11-29T23%3A16%3A46Z&se=2020-11-30T07%3A26%3A46Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_faa00506e59aafadb79280293bd47e16d9a9c9975fe3bb5ce60ac4932a251b15_d.txt\"], [\"logs/azureml/101_azureml.log\"]], \"run_duration\": \"0:07:18\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"train_batch_size\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [64]}]}, {\"name\": \"max_seq_length\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [128]}]}, {\"name\": \"warmup_steps\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [10]}]}, {\"name\": \"epochs\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [1]}]}, {\"name\": \"lr\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [0.5]}]}, {\"name\": \"adam_epsilon\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [0.2]}]}, {\"name\": \"use_fast_tokenizer\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [\"True\"]}]}, {\"name\": \"model_type\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [\"bert\"]}]}, {\"name\": \"grad_accumulation_steps\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [1]}]}, {\"name\": \"logging_steps\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [1]}]}, {\"name\": \"save_steps\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [50]}]}, {\"name\": \"model_name\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [\"distilbert-base-multilingual-cased\"]}]}, {\"name\": \"do_lower_case\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [\"False\"]}]}, {\"name\": \"eval_f1\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9222771862161483]}]}, {\"name\": \"eval_recal\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [0.9259259259259259]}]}, {\"name\": \"eval_precision\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [0.918657090362452]}]}, {\"name\": \"eval_loss\", \"run_id\": \"ner_new_1606688308_21ae6f00\", \"categories\": [0], \"series\": [{\"data\": [0.04763645886515196]}]}], \"run_logs\": \"2020-11-29 22:19:10,716|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-11-29 22:19:10,717|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-11-29 22:19:10,724|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2020-11-29 22:19:10,724|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-11-29 22:19:11,092|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f46c96e51e0> for run source azureml.scriptrun\\n2020-11-29 22:19:11,122|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-11-29 22:19:11,130|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-11-29 22:19:11,131|azureml.core.authentication|DEBUG|Time to expire 1814364.868969 seconds\\n2020-11-29 22:19:11,131|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2020-11-29 22:19:11,131|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2020-11-29 22:19:11,175|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:11,176|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:11,176|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:11,176|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:11,176|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:11,177|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:11,177|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:11,215|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2020-11-29 22:19:11,215|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-11-29 22:19:11,274|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2020-11-29 22:19:11,275|azureml._SubmittedRun#ner_new_1606688308_21ae6f00|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '4859a9da-ee7e-41be-b247-0bfedf9d669d', 'azureml.git.repository_uri': 'git@github.com:zaradana/Fast_BERT.git', 'mlflow.source.git.repoURL': 'git@github.com:zaradana/Fast_BERT.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'c94b021530133e64594598ec2dd98736c5b33fe5', 'mlflow.source.git.commit': 'c94b021530133e64594598ec2dd98736c5b33fe5', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-11-29 22:19:11,275|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-11-29 22:19:11,275|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2020-11-29 22:19:11,275|azureml.WorkerPool|DEBUG|[START]\\n2020-11-29 22:19:11,275|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-11-29 22:19:11,276|azureml.RunStatusContext|DEBUG|[START]\\n2020-11-29 22:19:11,276|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-11-29 22:19:11,276|azureml.MetricsClient|DEBUG|[START]\\n2020-11-29 22:19:11,276|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2020-11-29 22:19:11,276|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-11-29 22:19:11,276|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-11-29 22:19:11,276|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/zd-ner/azureml/ner_new_1606688308_21ae6f00/mounts/workspaceblobstore/azureml/ner_new_1606688308_21ae6f00\\n2020-11-29 22:19:11,276|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-11-29 22:19:11,276|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/zd-ner/azureml/ner_new_1606688308_21ae6f00/mounts/workspaceblobstore/azureml/ner_new_1606688308_21ae6f00\\n2020-11-29 22:19:13,410|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-11-29 22:19:13,411|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:13,411|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:13,412|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:13,412|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:13,412|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:13,412|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:13,412|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-11-29 22:19:13,445|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2020-11-29 22:19:13,446|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-11-29 22:19:13,510|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2020-11-29 22:19:13,511|azureml._SubmittedRun#ner_new_1606688308_21ae6f00|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '4859a9da-ee7e-41be-b247-0bfedf9d669d', 'azureml.git.repository_uri': 'git@github.com:zaradana/Fast_BERT.git', 'mlflow.source.git.repoURL': 'git@github.com:zaradana/Fast_BERT.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'c94b021530133e64594598ec2dd98736c5b33fe5', 'mlflow.source.git.commit': 'c94b021530133e64594598ec2dd98736c5b33fe5', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-11-29 22:19:13,511|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-11-29 22:19:13,526|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-11-29 22:19:13,526|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-11-29 22:19:13,526|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-11-29 22:19:14,552|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-11-29 22:19:14,558|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-11-29 22:19:14,579|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 13.\\n2020-11-29 22:19:14,584|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-11-29 22:19:14,584|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-11-29 22:19:14,627|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 13 values.\\n2020-11-29 22:19:14,788|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-11-29 22:19:14,789|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-11-29 22:19:14,789|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[START]\\n2020-11-29 22:19:14,789|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-11-29 22:19:14,789|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2020-11-29 22:19:14,790|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling post_run_metrics with url /metric/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}/batch\\n2020-11-29 22:19:14,790|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-11-29 22:19:14,797|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-11-29 22:19:14,797|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-11-29 22:19:14,797|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-11-29 22:19:14,797|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-11-29 22:19:14,798|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-11-29 22:19:14,798|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-11-29 22:19:14,798|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-11-29 22:19:15,516|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[STOP]\\n2020-11-29 22:19:41,123|azureml.core.authentication|DEBUG|Time to expire 1814334.876461 seconds\\n2020-11-29 22:20:11,123|azureml.core.authentication|DEBUG|Time to expire 1814304.876285 seconds\\n2020-11-29 22:20:41,123|azureml.core.authentication|DEBUG|Time to expire 1814274.87608 seconds\\n2020-11-29 22:21:11,124|azureml.core.authentication|DEBUG|Time to expire 1814244.875831 seconds\\n2020-11-29 22:21:41,124|azureml.core.authentication|DEBUG|Time to expire 1814214.875597 seconds\\n2020-11-29 22:22:11,124|azureml.core.authentication|DEBUG|Time to expire 1814184.875308 seconds\\n2020-11-29 22:22:41,124|azureml.core.authentication|DEBUG|Time to expire 1814154.875079 seconds\\n2020-11-29 22:23:11,125|azureml.core.authentication|DEBUG|Time to expire 1814124.874822 seconds\\n2020-11-29 22:23:41,125|azureml.core.authentication|DEBUG|Time to expire 1814094.87456 seconds\\n2020-11-29 22:24:11,125|azureml.core.authentication|DEBUG|Time to expire 1814064.874362 seconds\\n2020-11-29 22:24:41,125|azureml.core.authentication|DEBUG|Time to expire 1814034.874103 seconds\\n2020-11-29 22:25:11,126|azureml.core.authentication|DEBUG|Time to expire 1814004.87385 seconds\\n2020-11-29 22:25:34,875|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-11-29 22:25:34,875|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-11-29 22:25:34,876|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 4.\\n2020-11-29 22:25:34,876|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-11-29 22:25:34,876|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-11-29 22:25:34,876|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-11-29 22:25:34,876|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 4 values.\\n2020-11-29 22:25:34,877|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-11-29 22:25:34,877|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-11-29 22:25:34,877|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[START]\\n2020-11-29 22:25:34,877|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-11-29 22:25:34,879|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 1__log_batch_v2 to queue of approximate size: 1\\n2020-11-29 22:25:34,880|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling post_run_metrics with url /metric/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}/batch\\n2020-11-29 22:25:34,880|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-11-29 22:25:34,885|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-11-29 22:25:34,887|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-11-29 22:25:34,887|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-11-29 22:25:34,887|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-11-29 22:25:34,887|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-11-29 22:25:34,888|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-11-29 22:25:35,053|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[STOP]\\n2020-11-29 22:25:37,965|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-11-29 22:25:37,966|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/zd-ner/azureml/ner_new_1606688308_21ae6f00/mounts/workspaceblobstore/azureml/ner_new_1606688308_21ae6f00\\n2020-11-29 22:25:37,966|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/zd-ner/azureml/ner_new_1606688308_21ae6f00/mounts/workspaceblobstore/azureml/ner_new_1606688308_21ae6f00 to /mnt/batch/tasks/shared/LS_root/jobs/zd-ner/azureml/ner_new_1606688308_21ae6f00/mounts/workspaceblobstore/azureml/ner_new_1606688308_21ae6f00\\n2020-11-29 22:25:37,966|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/zd-ner/azureml/ner_new_1606688308_21ae6f00/mounts/workspaceblobstore/azureml/ner_new_1606688308_21ae6f00\\n2020-11-29 22:25:37,966|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-11-29 22:25:37,966|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-11-29 22:25:37,966|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-11-29 22:25:37,966|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-11-29 22:25:37,966|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-11-29 22:25:37,967|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-11-29 22:25:37,967|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-11-29 22:25:37,967|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-11-29 22:25:37,967|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-11-29 22:25:37,967|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-11-29 22:25:37,967|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:37,967|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-11-29 22:25:37,967|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-11-29 22:25:37,968|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-11-29 22:25:37,968|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-11-29 22:25:37,968|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-11-29 22:25:37,968|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-11-29 22:25:37,968|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-11-29 22:25:37,968|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:37,968|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:37,968|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-11-29 22:25:37,969|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-11-29 22:25:38,047|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-11-29 22:25:38,047|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,047|azureml.MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,047|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-11-29 22:25:38,048|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,049|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,049|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-11-29 22:25:38,049|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-11-29 22:25:38,106|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-11-29 22:25:38,106|azureml.RunStatusContext|DEBUG|[STOP]\\n2020-11-29 22:25:38,106|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,106|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,106|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-11-29 22:25:38,106|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-11-29 22:25:38,106|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-11-29 22:25:38,107|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-11-29 22:25:38,171|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-11-29 22:25:38,171|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,171|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-11-29 22:25:38,171|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-11-29 22:25:38,172|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-11-29 22:25:38,172|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,172|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-11-29 22:25:38,172|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-11-29 22:25:38,172|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-11-29 22:25:38,172|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,172|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-11-29 22:25:38,172|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [AsyncTask(0__log_batch_v2), AsyncTask(1__log_batch_v2)].\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[START]\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-11-29 22:25:38,173|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-11-29 22:25:38,174|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-11-29 22:25:38,237|azureml._SubmittedRun#ner_new_1606688308_21ae6f00.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-11-29 22:25:38,238|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2020-11-29 22:25:38,238|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2020-11-29 22:25:38,238|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2020-11-29 22:25:38,238|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.18.0\"}, \"loading\": false}"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "src = ScriptRunConfig(source_directory=\".\",\n",
    "                      script='train.py',\n",
    "                      arguments=[\"--json_config\", \"training_config.json\"],\n",
    "                      compute_target=\"zd-ner\",\n",
    "                      environment=pytorch_env)\n",
    "run = experiment.submit(src)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, uniform, PrimaryMetricGoal\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "        'lr': uniform(0.01, 1),\n",
    "        'adam_epsilon': uniform(0.01, 1)\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
    "                                     hyperparameter_sampling=param_sampling, \n",
    "                                     policy=early_termination_policy,\n",
    "                                     primary_metric_name='eval_f1',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=2,\n",
    "                                     max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_config)\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best Run is:\\n  eval_f1: {0:.5f} \\n  learning rate: {1:.5f} \\n  adam_epsilon: {2:.5f}'\n",
    ".format(\n",
    "        best_run_metrics['eval_f1'],\n",
    "        best_run_metrics['lr'],\n",
    "        best_run_metrics['adam_epsilon'])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = azureml.core.ScriptRun(experiment=Experiment(ws, name=\"ner\"),run_id=\"ner_new_1606688308_21ae6f00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ner\tner:9\t9\n"
     ]
    }
   ],
   "source": [
    "model = best_run.register_model(model_name = 'ner', model_path = './outputs')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running...................................................................\n",
      "Failed\n",
      "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
      "Operation ID: 3ac074d6-5cbf-418c-9b75-e9258e0b04c2\n",
      "More information can be found using '.get_logs()'\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"AciDeploymentFailed\",\n",
      "  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"code\": \"CrashLoopBackOff\",\n",
      "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"AciDeploymentFailed\",\n",
      "      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":4,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off 1m20s restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2020-11-29T23:36:39Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2020-11-29T23:36:43Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2020-11-29T23:32:08Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:35:02Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:51Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:51Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"name\\\":\\\"Created\\\",\\\"message\\\":\\\"Created container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-11-29T23:35:07Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:36:24Z\\\",\\\"name\\\":\\\"BackOff\\\",\\\"message\\\":\\\"Back-off restarting failed container\\\",\\\"type\\\":\\\"Warning\\\"}]}\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 3ac074d6-5cbf-418c-9b75-e9258e0b04c2\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":4,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off 1m20s restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2020-11-29T23:36:39Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2020-11-29T23:36:43Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2020-11-29T23:32:08Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:35:02Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:51Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:51Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"name\\\":\\\"Created\\\",\\\"message\\\":\\\"Created container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-11-29T23:35:07Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:36:24Z\\\",\\\"name\\\":\\\"BackOff\\\",\\\"message\\\":\\\"Back-off restarting failed container\\\",\\\"type\\\":\\\"Warning\\\"}]}\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 3ac074d6-5cbf-418c-9b75-e9258e0b04c2\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\\\\\"restartCount\\\\\\\":4,\\\\\\\"currentState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Waiting\\\\\\\",\\\\\\\"startTime\\\\\\\":null,\\\\\\\"exitCode\\\\\\\":null,\\\\\\\"finishTime\\\\\\\":null,\\\\\\\"detailStatus\\\\\\\":\\\\\\\"CrashLoopBackOff: Back-off 1m20s restarting failed\\\\\\\"},\\\\\\\"previousState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Terminated\\\\\\\",\\\\\\\"startTime\\\\\\\":\\\\\\\"2020-11-29T23:36:39Z\\\\\\\",\\\\\\\"exitCode\\\\\\\":111,\\\\\\\"finishTime\\\\\\\":\\\\\\\"2020-11-29T23:36:43Z\\\\\\\",\\\\\\\"detailStatus\\\\\\\":\\\\\\\"Error\\\\\\\"},\\\\\\\"events\\\\\\\":[{\\\\\\\"count\\\\\\\":2,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:32:08Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:35:02Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"pulling image \\\\\\\\\\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:51Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:51Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:52Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:52Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Created\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Created container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:52Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:52Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Started container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":6,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:35:07Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:36:24Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"BackOff\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Back-off restarting failed container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Warning\\\\\\\"}]}\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-604372fb009f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                            \u001b[0minference_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                            deployment_config=aciconfig)\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Onedrive/multifit_ner/env/lib/python3.8/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    804\u001b[0m                     \u001b[0mlogs_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Current sub-operation type not known, more logs unavailable.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                 raise WebserviceException('Service deployment polling reached non-successful terminal state, current '\n\u001b[0m\u001b[1;32m    807\u001b[0m                                           \u001b[0;34m'service state: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                                           \u001b[0;34m'Operation ID: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 3ac074d6-5cbf-418c-9b75-e9258e0b04c2\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":4,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off 1m20s restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2020-11-29T23:36:39Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2020-11-29T23:36:43Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2020-11-29T23:32:08Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:35:02Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:51Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:51Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"name\\\":\\\"Created\\\",\\\"message\\\":\\\"Created container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:34:52Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-11-29T23:35:07Z\\\",\\\"lastTimestamp\\\":\\\"2020-11-29T23:36:24Z\\\",\\\"name\\\":\\\"BackOff\\\",\\\"message\\\":\\\"Back-off restarting failed container\\\",\\\"type\\\":\\\"Warning\\\"}]}\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 3ac074d6-5cbf-418c-9b75-e9258e0b04c2\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: nertenscript. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image 91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\\\\\"restartCount\\\\\\\":4,\\\\\\\"currentState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Waiting\\\\\\\",\\\\\\\"startTime\\\\\\\":null,\\\\\\\"exitCode\\\\\\\":null,\\\\\\\"finishTime\\\\\\\":null,\\\\\\\"detailStatus\\\\\\\":\\\\\\\"CrashLoopBackOff: Back-off 1m20s restarting failed\\\\\\\"},\\\\\\\"previousState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Terminated\\\\\\\",\\\\\\\"startTime\\\\\\\":\\\\\\\"2020-11-29T23:36:39Z\\\\\\\",\\\\\\\"exitCode\\\\\\\":111,\\\\\\\"finishTime\\\\\\\":\\\\\\\"2020-11-29T23:36:43Z\\\\\\\",\\\\\\\"detailStatus\\\\\\\":\\\\\\\"Error\\\\\\\"},\\\\\\\"events\\\\\\\":[{\\\\\\\"count\\\\\\\":2,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:32:08Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:35:02Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"pulling image \\\\\\\\\\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:51Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:51Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"91000ffe28554e43abd795dd11872a0e.azurecr.io/azureml/azureml_e0a06ef6921b9e6c8f7cc64a6347e096\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:52Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:52Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Created\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Created container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:52Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:34:52Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Started container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":6,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:35:07Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-11-29T23:36:24Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"BackOff\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Back-off restarting failed container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Warning\\\\\\\"}]}\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "#remote deploy\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "dockerfile = r\"\"\"\n",
    "FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\n",
    "RUN python -c \"import nltk; nltk.download('punkt')\"\n",
    "\"\"\"\n",
    "\n",
    "env = Environment.from_conda_specification(name=\"env\", file_path=\"conda.yaml\")\n",
    "env.docker.base_image = None\n",
    "env.docker.base_dockerfile = dockerfile\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=2, \n",
    "                                               memory_gb=10, \n",
    "                                               tags={'data': 'text',  'method':'DistillBert-NER', 'framework':'pytorch'},\n",
    "                                               description='Classify PER, LOC, ORG, and MISC')\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                           name='ner', \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Error in environment creation, more details may be found here: https://zdner7033739836.blob.core.windows.net/azureml/ImageLogs/19fd262d-863d-4e5a-8397-98a10fffe002/build.log?sv=2019-02-02&sr=b&sig=%2FnQH4g1mD5mELgZ9ZhQ8j9MZaZ7%2FaUsEO%2B8ZWulP4%2BU%3D&st=2020-11-29T23%3A08%3A47Z&se=2020-11-30T07%3A13%3A47Z&sp=r '"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring URI is: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Scoring URI is: {}\".format(service.scoring_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/azureml-envs/azureml_6a6384407022fe87d6a235546547dbe0/nltk_data'\n    - '/azureml-envs/azureml_6a6384407022fe87d6a235546547dbe0/share/nltk_data'\n    - '/azureml-envs/azureml_6a6384407022fe87d6a235546547dbe0/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "response = requests.post(url=service.scoring_uri, data=json.dumps(\"Steve went to London\"),headers={\"Content-type\": \"application/json\"})\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}